{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "I am using cython because it allows me to speed up the training of the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython -- WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%cython` not found.\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "%%cython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Progetto_Ing_Informatica\\Master\\RecSys\n"
     ]
    }
   ],
   "source": [
    "%cd ./RecSys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.ma import MaskedArray\n",
    "import sklearn.utils.fixes\n",
    "import scipy.sparse as sps\n",
    "import functions\n",
    "from Evaluation.Evaluator import EvaluatorHoldout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_PATH= 'Data/interactions_and_impressions.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of interactions is 5826506\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_PATH,\n",
    "                                sep=\",\",\n",
    "                                header=0, engine='python')\n",
    "URM_all_dataframe.columns = [\"UserID\", \"ItemID\", \"Impressions\", \"Data\"]\n",
    "\n",
    "print(\"The number of interactions is {}\".format(len(URM_all_dataframe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>20,21,22,23,24,25,26,27,28,29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  ItemID                                        Impressions  Data\n",
       "0       0      11  0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19     1\n",
       "1       0      21                                                NaN     0\n",
       "2       0      21                                                NaN     0\n",
       "3       0      21                      20,21,22,23,24,25,26,27,28,29     0\n",
       "4       0      21                                                NaN     1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all_dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID_unique = URM_all_dataframe[\"UserID\"].unique()\n",
    "itemID_unique = URM_all_dataframe[\"ItemID\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(userID_unique)\n",
    "n_items = len(itemID_unique)\n",
    "n_iteractions = len(URM_all_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items\t 24507, Number of users\t 41629\n",
      "Max ID items\t 24506, Max Id users\t 41628\n",
      "\n",
      "Number of interactions\t 5826506\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of items\\t {}, Number of users\\t {}\".format(n_items, n_users))\n",
    "print(\"Max ID items\\t {}, Max Id users\\t {}\\n\".format(max(itemID_unique), max(userID_unique)))\n",
    "print(\"Number of interactions\\t {}\".format(n_iteractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average interactions per user 139.96\n",
      "Average interactions per item 237.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average interactions per user {:.2f}\".format(n_iteractions / n_users))\n",
    "print(\"Average interactions per item {:.2f}\\n\".format(n_iteractions / n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity 99.43 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity {:.2f} %\".format((1 - float((n_iteractions) / (n_items * n_users))) * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_RATIO = 0.15\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "NUM_LATENT_FACTORS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "REGULARIZATION= 1e-5\n",
    "\n",
    "DESTINATION_PATH = 'Data/data_target_users_test.csv'\n",
    "\n",
    "WISE_USER = False # If True, select the number of interactions one user at a time. Otherwise, globally."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implict URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 107 (0.26 %) of 41629 users have no sampled items\n",
      "Warning: 968 (2.33 %) of 41629 users have no train items\n",
      "Warning: 2825 (6.79 %) of 41629 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "#Create a binary matrix with one per each interaction\n",
    "URM_all = sps.coo_matrix((np.ones(len(URM_all_dataframe[\"Data\"].values)),\n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr()  # to obtain fast access to rows (users)\n",
    "\n",
    "URM_train, URM_validation, URM_test = functions.split_train_in_three_percetanges(URM_all, WISE_USER, VALIDATION_RATIO, TEST_RATIO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 968 ( 2.3%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 2825 ( 6.8%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "# create an evaluator object to evaluate validation set\n",
    "# will use it for hyperparameter tuning\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Recommenders.MatrixFactorization.IALSRecommender as recsys\n",
    "\n",
    "recommender_class = recsys.IALSRecommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m metric_to_optimize \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMAP\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m cutoff_to_optimize \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskopt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspace\u001b[39;00m \u001b[39mimport\u001b[39;00m Real, Integer, Categorical\n\u001b[0;32m      9\u001b[0m hyperparameters_range_dictionary \u001b[39m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39ml1_ratio\u001b[39m\u001b[39m\"\u001b[39m: Real(low \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m, high \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m, prior \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlog-uniform\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m#prior = log-uniform means that valeus\u001b[39;00m\n\u001b[0;32m     11\u001b[0m                                                 \u001b[39m# are sampled uniformly between log(lower, base) and log(upper, base)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtopK\u001b[39m\u001b[39m\"\u001b[39m: Integer(\u001b[39m200\u001b[39m,\u001b[39m450\u001b[39m)\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m \u001b[39m#Setup the early stopping --> to save a lot of computational time\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "#start Hyperparameter tuning\n",
    "n_cases = 50\n",
    "n_random_starts = int(n_cases*0.3)\n",
    "metric_to_optimize = \"MAP\"\n",
    "cutoff_to_optimize = 10\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "\n",
    "hyperparameters_range_dictionary = {\n",
    "    \"l1_ratio\": Real(low = 0.001, high = 0.01, prior = 'log-uniform'), #prior = log-uniform means that valeus\n",
    "                                                # are sampled uniformly between log(lower, base) and log(upper, base)\n",
    "                                                # (default base is 10)\n",
    "    \"alpha\": Real(low = 0.01, high = 0.1, prior = 'log-uniform'), #low and high are the lower bound and the upper bound\n",
    "    \"positive_only\": Categorical([True]),\n",
    "    \"topK\": Integer(200,450)\n",
    "}\n",
    "\n",
    "#Setup the early stopping --> to save a lot of computational time\n",
    "earlystopping_keywargs = {\"validation_every_n\": 5,\n",
    "                          \"stop_on_validation\": True,\n",
    "                          \"evaluator_object\": evaluator_validation,\n",
    "                          \"lower_validations_allowed\": 5,\n",
    "                          \"validation_metric\": metric_to_optimize,\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperparameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\n",
    "\n",
    "#create a bayesian optimizer object, we pass the recommender and the evaluator\n",
    "hyperparameterSearch = SearchBayesianSkopt(recommender_class,\n",
    "                                         evaluator_validation=evaluator_validation,\n",
    "                                         evaluator_test=evaluator_test)\n",
    "                                         \n",
    "from HyperparameterTuning.SearchAbstractClass import SearchInputRecommenderArgs\n",
    "\n",
    "#provide data needed to create instance of model (one on URM_train, the other on URM_all)\n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train],     # For a CBF model simply put [URM_train, ICM_train]\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = earlystopping_keywargs\n",
    ")\n",
    "recommender_input_args_last_test = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train_validation],\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = earlystopping_keywargs\n",
    ")\n",
    "#let's run the bayesian search\n",
    "hyperparameterSearch.search(recommender_input_args = recommender_input_args,\n",
    "                       recommender_input_args_last_test = recommender_input_args_last_test,\n",
    "                       hyperparameter_search_space = hyperparameters_range_dictionary,\n",
    "                       n_cases = n_cases,\n",
    "                       n_random_starts = n_random_starts,\n",
    "                       save_model = \"last\",\n",
    "                       output_folder_path = output_folder_path, # Where to save the results\n",
    "                       output_file_name_root = recommender_class.RECOMMENDER_NAME, # How to call the files\n",
    "                       metric_to_optimize = metric_to_optimize,\n",
    "                       cutoff_to_optimize = cutoff_to_optimize,\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.DataIO import DataIO\n",
    "\n",
    "#explore the results of the search\n",
    "data_loader = DataIO(folder_path = output_folder_path)\n",
    "search_metadata = data_loader.load_data(recommender_class.RECOMMENDER_NAME + \"_metadata.zip\")\n",
    "\n",
    "search_metadata.keys()\n",
    "hyperparameters_df = search_metadata[\"hyperparameters_df\"]\n",
    "result_on_validation_df = search_metadata[\"result_on_validation_df\"]\n",
    "best_hyperparameters = search_metadata[\"hyperparameters_best\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperparameters_df)\n",
    "print(result_on_validation_df)\n",
    "print(best_hyperparameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funk SVD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the RecSys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = recsys.IALSRecommender(URM_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.fit(self, epochs = 300,\n",
    "            num_factors = NUM_LATENT_FACTORS,\n",
    "            confidence_scaling = \"linear\",\n",
    "            alpha = 1.0,\n",
    "            epsilon = 1.0,\n",
    "            reg = REGULARIZATION,\n",
    "            init_mean=0.0,\n",
    "            init_std=0.1,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.save_model(output_folder_path, file_name=recommender.RECOMMENDER_NAME + \"_my_own_save.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = pd.read_csv(DESTINATION_PATH)\n",
    "\n",
    "user_id = test_users['user_id']\n",
    "recommendations = []\n",
    "for user in user_id:\n",
    "    recommendations.append(recommender.recommend(user, cutoff=10))\n",
    "for index in range(len(recommendations)):\n",
    "    recommendations[index] = np.array(recommendations[index])\n",
    "\n",
    "test_users['item_list'] = recommendations\n",
    "test_users['item_list'] = pd.DataFrame(\n",
    "    [str(line).strip('[').strip(']').replace(\"'\", \"\") for line in test_users['item_list']])\n",
    "test_users.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e20945caac25609d339b20d8cf37beb8ee9d6d19ccbfb129cd26220d3f01bf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
