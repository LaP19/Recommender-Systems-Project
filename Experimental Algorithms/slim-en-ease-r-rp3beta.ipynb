{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f3dd31",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-16T23:50:10.283520Z",
     "iopub.status.busy": "2023-01-16T23:50:10.282904Z",
     "iopub.status.idle": "2023-01-16T23:53:08.864955Z",
     "shell.execute_reply": "2023-01-16T23:53:08.863741Z"
    },
    "papermill": {
     "duration": 178.591596,
     "end_time": "2023-01-16T23:53:08.867928",
     "exception": false,
     "start_time": "2023-01-16T23:50:10.276332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\r\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/conda/bin/python'\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KMatrixFactorization_Cython_Epoch.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KMatrixFactorization_Cython_Epoch.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_pf_32MatrixFactorization_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_end_pos_seen_items\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      " 8669 |         \u001B[01;35m\u001B[Kfor\u001B[m\u001B[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |         \u001B[01;35m\u001B[K^~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_start_pos_seen_items\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KMatrixFactorizationImpressions_Cython_Epoch.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_f_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_sampleBPR_Cython\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KMatrixFactorizationImpressions_Cython_Epoch.c:12758:17:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_start_pos_impression_items\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      "12758 |       \u001B[01;35m\u001B[K__pyx_t_4 = (__pyx_v_start_pos_impression_items + __pyx_v_index)\u001B[m\u001B[K;\r\n",
      "      |       \u001B[01;35m\u001B[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_pf_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_end_pos_seen_items\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      " 8736 |       \u001B[01;35m\u001B[Kfor\u001B[m\u001B[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |       \u001B[01;35m\u001B[K^~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_start_pos_seen_items\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KCompute_Similarity_Cython.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\r\n",
      "\r\n",
      "Compiling [4/10]: Sparse_Matrix_Tree_CSR.pyx... \r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KSparse_Matrix_Tree_CSR.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KSparse_Matrix_Tree_CSR.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_f_22Sparse_Matrix_Tree_CSR_22Sparse_Matrix_Tree_CSR_test_list_tree_conversion\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KSparse_Matrix_Tree_CSR.c:5844:15:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_previous_element\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      " 5844 |     \u001B[01;35m\u001B[K__pyx_t_7 = __pyx_v_current_element->lower\u001B[m\u001B[K;\r\n",
      "      |     \u001B[01;35m\u001B[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [4/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\r\n",
      "\r\n",
      "Compiling [5/10]: Triangular_Matrix.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KTriangular_Matrix.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [5/10]: Triangular_Matrix.pyx... PASS\r\n",
      "\r\n",
      "Compiling [6/10]: SLIM_BPR_Cython_Epoch.pyx... \r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KSLIM_BPR_Cython_Epoch.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KSLIM_BPR_Cython_Epoch.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_f_21SLIM_BPR_Cython_Epoch_22Sparse_Matrix_Tree_CSR_test_list_tee_conversion\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KSLIM_BPR_Cython_Epoch.c:10848:15:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_previous_element\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      "10848 |     \u001B[01;35m\u001B[K__pyx_t_7 = __pyx_v_current_element->lower\u001B[m\u001B[K;\r\n",
      "      |     \u001B[01;35m\u001B[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [6/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [7/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KCFW_DVV_Similarity_Cython_SGD.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [7/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KFBSM_Rating_Cython_SGD.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KFBSM_Rating_Cython_SGD.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_pf_22FBSM_Rating_Cython_SGD_22FBSM_Rating_Cython_SGD_2fit\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KFBSM_Rating_Cython_SGD.c:9031:55:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_num_sample\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      " 9031 |   __pyx_t_5 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001B[01;35m\u001B[K((double)__pyx_v_num_sample)\u001B[m\u001B[K)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 551, __pyx_L1_error)\r\n",
      "      |                                                      \u001B[01;35m\u001B[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [9/10]: CFW_D_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KCFW_D_Similarity_Cython_SGD.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KCFW_D_Similarity_Cython_SGD.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_pf_27CFW_D_Similarity_Cython_SGD_27CFW_D_Similarity_Cython_SGD_6fit\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KCFW_D_Similarity_Cython_SGD.c:6056:55:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_sample_num\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      " 6056 |   __pyx_t_3 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001B[01;35m\u001B[K((double)__pyx_v_sample_num)\u001B[m\u001B[K)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 290, __pyx_L1_error)\r\n",
      "      |                                                      \u001B[01;35m\u001B[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [9/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [10/10]: HP3_Similarity_Cython_SGD.pyx... \r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "In file included from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001B[m\u001B[K,\r\n",
      "                 from \u001B[01m\u001B[KHP3_Similarity_Cython_SGD.c:746\u001B[m\u001B[K:\r\n",
      "\u001B[01m\u001B[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001B[01;35m\u001B[K-Wcpp\u001B[m\u001B[K]\r\n",
      "   17 | #\u001B[01;35m\u001B[Kwarning\u001B[m\u001B[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001B[01;35m\u001B[K^~~~~~~\u001B[m\u001B[K\r\n",
      "\u001B[01m\u001B[KHP3_Similarity_Cython_SGD.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_pf_25HP3_Similarity_Cython_SGD_25HP3_Similarity_Cython_SGD_4fit\u001B[m\u001B[K’:\r\n",
      "\u001B[01m\u001B[KHP3_Similarity_Cython_SGD.c:6303:55:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[K‘\u001B[01m\u001B[K__pyx_v_sample_num\u001B[m\u001B[K’ may be used uninitialized in this function [\u001B[01;35m\u001B[K-Wmaybe-uninitialized\u001B[m\u001B[K]\r\n",
      " 6303 |   __pyx_t_1 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001B[01;35m\u001B[K((double)__pyx_v_sample_num)\u001B[m\u001B[K)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)\r\n",
      "      |                                                      \u001B[01;35m\u001B[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "Compiling [10/10]: HP3_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\r\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\r\n"
     ]
    }
   ],
   "source": [
    "from numpy.ma import MaskedArray\n",
    "import sklearn.utils.fixes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sklearn.utils.fixes.MaskedArray = MaskedArray\n",
    "\n",
    "import os\n",
    "os.system(r\"run_compile_all_cython.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33c06ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T23:53:08.884433Z",
     "iopub.status.busy": "2023-01-16T23:53:08.884029Z",
     "iopub.status.idle": "2023-01-16T23:53:40.485604Z",
     "shell.execute_reply": "2023-01-16T23:53:40.484730Z"
    },
    "papermill": {
     "duration": 31.619559,
     "end_time": "2023-01-16T23:53:40.494723",
     "exception": false,
     "start_time": "2023-01-16T23:53:08.875164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of interactions is 5826506\n",
      "Number of items\t 24507, Number of users\t 41629\n",
      "Max ID items\t 24506, Max Id users\t 41628\n",
      "\n",
      "Average interactions per user 139.96\n",
      "Average interactions per item 237.75\n",
      "\n",
      "Sparsity 99.43 %\n",
      "Warning: 332 (0.80 %) of 41629 users have no sampled items\n",
      "Warning: 768 (1.84 %) of 41629 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 768 ( 1.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 332 ( 0.8%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "\n",
    "sklearn.utils.fixes.MaskedArray = MaskedArray\n",
    "\n",
    "# Load the data\n",
    "URM_path = 'Data/interactions_and_impressions.csv'\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                sep=\",\",\n",
    "                                header=0, engine='python')\n",
    "URM_all_dataframe.columns = [\"UserID\", \"ItemID\", \"Impressions\", \"Data\"]\n",
    "\n",
    "print(\"The number of interactions is {}\".format(len(URM_all_dataframe)))\n",
    "\n",
    "userID_unique = URM_all_dataframe[\"UserID\"].unique()\n",
    "itemID_unique = URM_all_dataframe[\"ItemID\"].unique()\n",
    "\n",
    "n_users = len(userID_unique)\n",
    "n_items = len(itemID_unique)\n",
    "n_interactions = len(URM_all_dataframe)\n",
    "print(\"Number of items\\t {}, Number of users\\t {}\".format(n_items, n_users))\n",
    "print(\"Max ID items\\t {}, Max Id users\\t {}\\n\".format(max(itemID_unique), max(userID_unique)))\n",
    "print(\"Average interactions per user {:.2f}\".format(n_interactions / n_users))\n",
    "print(\"Average interactions per item {:.2f}\\n\".format(n_interactions / n_items))\n",
    "\n",
    "print(\"Sparsity {:.2f} %\".format((1 - float(n_interactions) / (n_items * n_users)) * 100))\n",
    "\n",
    "# Build the URM: I turn every kind of interaction as a 1, so I first eliminate all the duplicate and then turn every\n",
    "# value remained in the Data of the iteractions_and_impressions into a 1\n",
    "URM_all_dataframe = URM_all_dataframe.drop_duplicates(['UserID', 'ItemID'], keep='first')\n",
    "\n",
    "URM_all = sps.coo_matrix((np.ones(len(URM_all_dataframe[\"Data\"].values)),\n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr()  # to obtain fast access to rows (users)\n",
    "\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import \\\n",
    "    split_train_in_two_percentage_global_sample\n",
    "\n",
    "# split data into train and validation data\n",
    "URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage=0.80)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=0.80)\n",
    "\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "# create an evaluator object to evaluate validation set\n",
    "# will use it for hyperparameter tuning\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579f58ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T23:53:40.511074Z",
     "iopub.status.busy": "2023-01-16T23:53:40.509952Z",
     "iopub.status.idle": "2023-01-16T23:53:40.803482Z",
     "shell.execute_reply": "2023-01-16T23:53:40.802264Z"
    },
    "papermill": {
     "duration": 0.304691,
     "end_time": "2023-01-16T23:53:40.806282",
     "exception": false,
     "start_time": "2023-01-16T23:53:40.501591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "        \n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "            \n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "            \n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "                    \n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af682bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T23:53:40.822627Z",
     "iopub.status.busy": "2023-01-16T23:53:40.821677Z",
     "iopub.status.idle": "2023-01-17T00:09:51.295323Z",
     "shell.execute_reply": "2023-01-17T00:09:51.294165Z"
    },
    "papermill": {
     "duration": 970.484549,
     "end_time": "2023-01-17T00:09:51.297941",
     "exception": false,
     "start_time": "2023-01-16T23:53:40.813392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 6319 (25.8%) in 5.00 min. Items per second: 21.06\n",
      "SLIMElasticNetRecommender: Processed 14083 (57.5%) in 10.00 min. Items per second: 23.47\n",
      "SLIMElasticNetRecommender: Processed 22561 (92.1%) in 15.00 min. Items per second: 25.06\n",
      "SLIMElasticNetRecommender: Processed 24507 (100.0%) in 16.17 min. Items per second: 25.25\n"
     ]
    }
   ],
   "source": [
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_train)\n",
    "recommender_SLIMElasticNet.fit(epochs = 700, l1_ratio=0.049999999999999996, alpha = 0.001, positive_only = True, topK = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b73e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-17T00:09:51.313957Z",
     "iopub.status.busy": "2023-01-17T00:09:51.313555Z",
     "iopub.status.idle": "2023-01-17T00:10:05.517021Z",
     "shell.execute_reply": "2023-01-17T00:10:05.515826Z"
    },
    "papermill": {
     "duration": 14.214365,
     "end_time": "2023-01-17T00:10:05.519620",
     "exception": false,
     "start_time": "2023-01-17T00:09:51.305255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: Similarity column 24507 (100.0%), 2291.17 column/sec. Elapsed time 10.70 sec\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "recommender_RP3beta = RP3betaRecommender(URM_train)\n",
    "recommender_RP3beta.fit(alpha = 0.6466715570981898, beta = 0.2703618471526261, topK = 80, implicit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d896cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-17T00:10:05.536832Z",
     "iopub.status.busy": "2023-01-17T00:10:05.536137Z",
     "iopub.status.idle": "2023-01-17T00:20:37.284770Z",
     "shell.execute_reply": "2023-01-17T00:20:37.283701Z"
    },
    "papermill": {
     "duration": 631.760333,
     "end_time": "2023-01-17T00:20:37.287544",
     "exception": false,
     "start_time": "2023-01-17T00:10:05.527211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 10.51 min\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "recommender_EASE_R = EASE_R_Recommender(URM_train)\n",
    "recommender_EASE_R.fit(topK = None, normalize_matrix = False, l2_norm = 93.68456224396647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d72e77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-17T00:20:37.304952Z",
     "iopub.status.busy": "2023-01-17T00:20:37.304498Z",
     "iopub.status.idle": "2023-01-17T00:20:37.316524Z",
     "shell.execute_reply": "2023-01-17T00:20:37.315531Z"
    },
    "papermill": {
     "duration": 0.023636,
     "end_time": "2023-01-17T00:20:37.318896",
     "exception": false,
     "start_time": "2023-01-17T00:20:37.295260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        self.recommender_3 = recommender_3\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, norm, alpha = 0.5, beta = 0.5):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\n",
    "        \n",
    "        \n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_3 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * (1-self.alpha-self.beta)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a509087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-17T00:20:37.335591Z",
     "iopub.status.busy": "2023-01-17T00:20:37.334644Z",
     "iopub.status.idle": "2023-01-17T01:50:45.475045Z",
     "shell.execute_reply": "2023-01-17T01:50:45.472363Z"
    },
    "papermill": {
     "duration": 5408.167952,
     "end_time": "2023-01-17T01:50:45.494237",
     "exception": false,
     "start_time": "2023-01-17T00:20:37.326285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.40 min. Users per second: 488\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.0, Theta: 1.0, Result: 0.02141616001286537\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.31 min. Users per second: 520\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.1, Theta: 0.9, Result: 0.021979239139427977\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.31 min. Users per second: 520\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.2, Theta: 0.8, Result: 0.02232625377635229\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.31 min. Users per second: 518\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.3, Theta: 0.7, Result: 0.022438746070203304\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.32 min. Users per second: 516\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.4, Theta: 0.6, Result: 0.02246332611179229\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 512\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.5, Theta: 0.5, Result: 0.022409475329251482\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 512\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.6, Theta: 0.4, Result: 0.022319894625331956\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.52 min. Users per second: 449\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.7, Theta: 0.30000000000000004, Result: 0.022140120415981873\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 509\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.8, Theta: 0.19999999999999996, Result: 0.021944852331344956\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.9, Theta: 0.09999999999999998, Result: 0.02174049419576881\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.23 min. Users per second: 555\n",
      "Norm: 1, Alpha: 0.0, Beta: 1.0, Theta: 0.0, Result: 0.021533164312770213\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 506\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.0, Theta: 0.9, Result: 0.021858246288325747\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 508\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.1, Theta: 0.8, Result: 0.022326910280031174\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 506\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.2, Theta: 0.7, Result: 0.02256224354111019\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 511\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.3, Theta: 0.6000000000000001, Result: 0.02263124246623112\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.58 min. Users per second: 430\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.4, Theta: 0.5, Result: 0.022619993528193817\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 503\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.5, Theta: 0.4, Result: 0.022558069498488854\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 505\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.6, Theta: 0.30000000000000004, Result: 0.022461031262393724\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.7, Theta: 0.20000000000000007, Result: 0.022264357910266635\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.8, Theta: 0.09999999999999998, Result: 0.02207681345545015\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.29 min. Users per second: 529\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.9, Theta: 0.0, Result: 0.02184607669128299\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 505\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.0, Theta: 0.8, Result: 0.022173568113032935\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.1, Theta: 0.7000000000000001, Result: 0.022577493655415674\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.62 min. Users per second: 420\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.2, Theta: 0.6000000000000001, Result: 0.02272578676527353\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 511\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.3, Theta: 0.5, Result: 0.022790762177462655\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.4, Theta: 0.4, Result: 0.022730103568310477\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 507\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.5, Theta: 0.30000000000000004, Result: 0.02264550491154038\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 503\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.6, Theta: 0.20000000000000007, Result: 0.022519775716588687\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 506\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.7, Theta: 0.10000000000000009, Result: 0.02235789900176418\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.32 min. Users per second: 517\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.8, Theta: 0.0, Result: 0.022164090569537647\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.59 min. Users per second: 428\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.0, Theta: 0.7, Result: 0.022392261530864887\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 511\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.1, Theta: 0.6, Result: 0.02270771251975747\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 509\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.2, Theta: 0.49999999999999994, Result: 0.02284038356130247\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.3, Theta: 0.39999999999999997, Result: 0.022872963041949853\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.36 min. Users per second: 501\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.4, Theta: 0.29999999999999993, Result: 0.022849713488586013\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 514\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.5, Theta: 0.19999999999999996, Result: 0.022702651808705832\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 512\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.6, Theta: 0.09999999999999998, Result: 0.022576676910454112\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.28 min. Users per second: 530\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.7, Theta: 0.0, Result: 0.022432303399484176\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.61 min. Users per second: 422\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.0, Theta: 0.6, Result: 0.022555774649090355\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 507\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.1, Theta: 0.5, Result: 0.022805198460284472\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 503\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.2, Theta: 0.39999999999999997, Result: 0.02287266295372974\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 503\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.3, Theta: 0.3, Result: 0.022945299841544906\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 504\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.4, Theta: 0.19999999999999996, Result: 0.0228967982043646\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 504\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.5, Theta: 0.09999999999999998, Result: 0.022748425459445092\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.30 min. Users per second: 523\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.6, Theta: 0.0, Result: 0.022619920691247214\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.47 min. Users per second: 464\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.0, Theta: 0.5, Result: 0.02263583119386869\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.48 min. Users per second: 461\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.1, Theta: 0.4, Result: 0.022848959868978225\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.36 min. Users per second: 502\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.2, Theta: 0.3, Result: 0.022909466006122228\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.3, Theta: 0.2, Result: 0.022965300867089124\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 504\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.4, Theta: 0.09999999999999998, Result: 0.02287722254658873\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.30 min. Users per second: 525\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.5, Theta: 0.0, Result: 0.02276045715186882\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 506\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.0, Theta: 0.4, Result: 0.022692318673877433\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 507\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.1, Theta: 0.30000000000000004, Result: 0.02288341077357427\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.60 min. Users per second: 426\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.2, Theta: 0.2, Result: 0.02296718880074576\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.3, Theta: 0.10000000000000003, Result: 0.022954357844227655\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.30 min. Users per second: 525\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.4, Theta: 0.0, Result: 0.022888779342120448\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 503\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.0, Theta: 0.30000000000000004, Result: 0.02273020456887647\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 511\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.1, Theta: 0.20000000000000004, Result: 0.022895657092200778\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.2, Theta: 0.10000000000000003, Result: 0.022944130565761722\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.33 min. Users per second: 510\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.3, Theta: 5.551115123125783e-17, Result: 0.022949781741660874\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.34 min. Users per second: 509\n",
      "Norm: 1, Alpha: 0.8, Beta: 0.0, Theta: 0.19999999999999996, Result: 0.022742513041697398\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.59 min. Users per second: 428\n",
      "Norm: 1, Alpha: 0.8, Beta: 0.1, Theta: 0.09999999999999995, Result: 0.0228573468005927\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 506\n",
      "Norm: 1, Alpha: 0.8, Beta: 0.2, Theta: -5.551115123125783e-17, Result: 0.02287163449604335\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.35 min. Users per second: 504\n",
      "Norm: 1, Alpha: 0.9, Beta: 0.0, Theta: 0.09999999999999998, Result: 0.022752383904704576\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.37 min. Users per second: 497\n",
      "Norm: 1, Alpha: 0.9, Beta: 0.1, Theta: -2.7755575615628914e-17, Result: 0.022833443657027764\n",
      "----\n",
      "EvaluatorHoldout: Processed 40861 (100.0%) in 1.32 min. Users per second: 518\n",
      "Norm: 1, Alpha: 1.0, Beta: 0.0, Theta: 0.0, Result: 0.02270371328580809\n",
      "----\n",
      "Best model has MAP: 0.02296718880074576 with alpha: 0.6, beta: 0.2\n"
     ]
    }
   ],
   "source": [
    "#find the best model\n",
    "recommender_object = DifferentLossScoresHybridRecommender(URM_train, recommender_SLIMElasticNet, recommender_RP3beta, recommender_EASE_R)\n",
    "\n",
    "best_model = {\n",
    "    \"MAP\" : 0,\n",
    "    \"alpha\" : 0,\n",
    "    \"beta\" : 0,\n",
    "    \"norm\" : 0\n",
    "}\n",
    "\n",
    "norm = 1\n",
    "for alpha in np.arange(0.0, 1.1, 0.1):\n",
    "    for beta in np.arange(0.0, 1.1, 0.1):\n",
    "\n",
    "        #truncate digits since np.arange sometimes doesn't\n",
    "        alpha = round(alpha,1)\n",
    "        beta = round(beta,1)\n",
    "\n",
    "\n",
    "        #discard cases in which the sum is greater than 1 \n",
    "        if ( (alpha+beta) <= 1): \n",
    "            theta = round(1-alpha-beta,1)\n",
    "\n",
    "            print(\"----\")\n",
    "            recommender_object.fit(norm, alpha, beta)\n",
    "            result_df, _ = evaluator_validation.evaluateRecommender(recommender_object)\n",
    "            print(\"Norm: {}, Alpha: {}, Beta: {}, Theta: {}, Result: {}\".format(norm, alpha, beta, 1-alpha-beta, result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "        if result_df.loc[10][\"MAP\"] > best_model[\"MAP\"]:\n",
    "            best_model[\"MAP\"] = result_df.loc[10][\"MAP\"]\n",
    "            best_model[\"alpha\"] = alpha\n",
    "            best_model[\"beta\"] = beta\n",
    "\n",
    "print(\"----\")\n",
    "print(\"Best model has MAP: {} with alpha: {}, beta: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"beta\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d162be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-17T01:50:45.534042Z",
     "iopub.status.busy": "2023-01-17T01:50:45.532871Z",
     "iopub.status.idle": "2023-01-17T02:40:09.687208Z",
     "shell.execute_reply": "2023-01-17T02:40:09.684585Z"
    },
    "papermill": {
     "duration": 2964.177599,
     "end_time": "2023-01-17T02:40:09.690779",
     "exception": false,
     "start_time": "2023-01-17T01:50:45.513180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 2632 (10.7%) in 5.00 min. Items per second: 8.77\n",
      "SLIMElasticNetRecommender: Processed 5963 (24.3%) in 10.00 min. Items per second: 9.94\n",
      "SLIMElasticNetRecommender: Processed 8942 (36.5%) in 15.00 min. Items per second: 9.93\n",
      "SLIMElasticNetRecommender: Processed 12185 (49.7%) in 20.00 min. Items per second: 10.15\n",
      "SLIMElasticNetRecommender: Processed 15558 (63.5%) in 25.00 min. Items per second: 10.37\n",
      "SLIMElasticNetRecommender: Processed 19072 (77.8%) in 30.00 min. Items per second: 10.59\n",
      "SLIMElasticNetRecommender: Processed 22570 (92.1%) in 35.00 min. Items per second: 10.75\n",
      "SLIMElasticNetRecommender: Processed 24507 (100.0%) in 37.80 min. Items per second: 10.81\n",
      "RP3betaRecommender: Similarity column 24507 (100.0%), 1877.99 column/sec. Elapsed time 13.05 sec\n",
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 11.30 min\n"
     ]
    }
   ],
   "source": [
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_all)\n",
    "recommender_SLIMElasticNet.fit(epochs = 700, l1_ratio=0.049999999999999996, alpha = 0.001, positive_only = True, topK = 1000)\n",
    "\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "recommender_RP3beta = RP3betaRecommender(URM_all)\n",
    "recommender_RP3beta.fit(alpha = 0.6466715570981898, beta = 0.2703618471526261, topK = 80, implicit = True)\n",
    "\n",
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "recommender_EASE_R = EASE_R_Recommender(URM_all)\n",
    "recommender_EASE_R.fit(topK = None, normalize_matrix = False, l2_norm = 93.68456224396647)\n",
    "\n",
    "# final hybrid recommender which combine the 3 models with the best norm, alpha and beta found\n",
    "recommender = DifferentLossScoresHybridRecommender(URM_all, recommender_SLIMElasticNet, recommender_RP3beta, recommender_EASE_R)\n",
    "recommender.fit(norm = 1, alpha = 0.6, beta = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd324899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-17T02:40:09.728305Z",
     "iopub.status.busy": "2023-01-17T02:40:09.727363Z",
     "iopub.status.idle": "2023-01-17T02:41:53.286867Z",
     "shell.execute_reply": "2023-01-17T02:41:53.285641Z"
    },
    "papermill": {
     "duration": 103.582214,
     "end_time": "2023-01-17T02:41:53.289996",
     "exception": false,
     "start_time": "2023-01-17T02:40:09.707782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_users = pd.read_csv('Data/data_target_users_test.csv')\n",
    "\n",
    "user_id = test_users['user_id']\n",
    "recommendations = []\n",
    "for user in user_id:\n",
    "    recommendations.append(recommender.recommend(user,cutoff = 10))\n",
    "for index in range(len(recommendations)):\n",
    "    recommendations[index]=np.array(recommendations[index])\n",
    "    \n",
    "test_users['item_list']= recommendations\n",
    "test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "test_users.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08abff8",
   "metadata": {
    "papermill": {
     "duration": 0.016279,
     "end_time": "2023-01-17T02:41:53.324634",
     "exception": false,
     "start_time": "2023-01-17T02:41:53.308355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10313.063558,
   "end_time": "2023-01-17T02:41:54.789616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-16T23:50:01.726058",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
